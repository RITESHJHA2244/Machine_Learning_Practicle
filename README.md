ğŸ§ª Practical 1: Linear Regression using Normal Equation
ğŸ“Œ Objective

To implement Linear Regression using the Normal Equation method on the Iris dataset and visualize the relationship between features.

ğŸ“Š Dataset Used

Iris Dataset (First 50 samples)

Features:

Sepal Length

Sepal Width

ğŸ§  Concept Used

We used the Normal Equation:

ğ‘¤
=
(
ğ‘‹
ğ‘‡
ğ‘‹
)
âˆ’
1
ğ‘‹
ğ‘‡
ğ‘¦
w=(X
T
X)
âˆ’1
X
T
y

Where:

X â†’ Design matrix

y â†’ Target vector

w â†’ Weight vector (slope & intercept)

ğŸ“ˆ Output

Slope (m): 0.7985

Intercept (c): -0.5694

Scatter plot of Sepal Length vs Sepal Width

Regression Line visualization

ğŸ›  Libraries Used

NumPy

Matplotlib

Scikit-Learn (for dataset only)




ğŸ§ª Practical 2: Linear Regression using Scikit-Learn
ğŸ“Œ Objective

To perform Linear Regression using built-in Scikit-Learn model on a real-world dataset.

ğŸ“Š Dataset Used

California Housing Dataset

ğŸ§  Steps Performed

Load dataset

Split into training & testing set

Train LinearRegression model

Predict on test data

Evaluate model

ğŸ“Š Evaluation Metrics

Mean Squared Error (MSE): 0.5304

RÂ² Score: 0.6057

ğŸ“ˆ Visualization

Scatter plot of Actual vs Predicted values

Diagonal reference line

ğŸ›  Libraries Used

Scikit-Learn

Matplotlib

NumPy



ğŸ§ª Practical 3: Logistic Regression (Classification)
ğŸ“Œ Objective

To classify whether a user will purchase a product based on features like Age and Estimated Salary.

ğŸ“Š Dataset Used

log.csv (Social Network Ads dataset)

Features:

Gender

Age

Estimated Salary

Target:

Purchased (0 or 1)

ğŸ§  Steps Performed

Data preprocessing

Label Encoding

One Hot Encoding

Feature Scaling (StandardScaler)

Train Logistic Regression model

Model Evaluation

Confusion Matrix

ROC-AUC Score

Decision Boundary visualization

ğŸ“Š Model Performance

Accuracy: 0.80

Precision: 0.76

Recall: 0.59

F1-Score: 0.66

ROC-AUC Score: 0.90

ğŸ“ˆ Visualization

Confusion Matrix

Logistic Regression Decision Boundary


Practicle -4 date = 24 feb. 2026

ğŸ“‚ Project Description

In this project, I built a simple Neural Network using TensorFlow (Keras API) to solve the XOR problem.

The XOR problem is not linearly separable, so it requires hidden layers to learn nonlinear decision boundaries.


ğŸ§  XOR Neural Network â€“ TensorFlow Practice
ğŸ“Œ What I Learned

Built a Neural Network using TensorFlow (Keras)

Solved XOR classification problem

Used hidden layers (ReLU activation)

Applied Binary Crossentropy loss

Evaluated model using Accuracy & MSE

Plotted training loss graph

ğŸ›  Tech Stack

Python

TensorFlow / Keras

Matplotlib

âš™ï¸ Model Architecture

Input: 2 features

Hidden Layers: 100 â†’ 30 neurons (ReLU)

Output: 1 neuron (Sigmoid)

ğŸ“Š Training

Optimizer: Adam

Loss: Binary Crossentropy

Epochs: 200
